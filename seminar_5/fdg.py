"""
Домашнее задание
1. Найдите сайт, содержащий интересующий вас список или каталог. Это может быть список книг, фильмов, спортивных команд или что-то еще, что вас заинтересовало.
2. Создайте новый проект Scrapy и определите нового паука. С помощью атрибута start_urls укажите URL выбранной вами веб-страницы.

3. Определите метод парсинга для извлечения интересующих вас данных. Используйте селекторы XPath или CSS для навигации по HTML и извлечения данных. Возможно, потребуется извлечь данные с нескольких страниц или перейти по ссылкам на другие страницы.

4. Сохраните извлеченные данные в структурированном формате. Вы можете использовать оператор yield для возврата данных из паука, которые Scrapy может записать в файл в выбранном вами формате (например, JSON или CSV).

5. Конечным результатом работы должен быть код Scrapy Spider, а также пример выходных данных.

Не забывайте соблюдать правила robots.txt и условия обслуживания веб-сайта, а также ответственно подходите к использованию веб-скрейпинга.

"""

"""
pip install Scrapy
scrapy startproject country_scraper
scrapy genspider countries_spider en.wikipedia.org/wiki/List_of_sovereign_states
scrapy crawl countries_spider
scrapy crawl countries_spider -o countries.json
"""